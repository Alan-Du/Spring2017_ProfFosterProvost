{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ipython notebooks and data files\n",
    "\n",
    "Spring 2017 - Prof. Foster Provost\n",
    "\n",
    "Teacher Assistant: Maria L Zamora Maass\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python\n",
    "\n",
    "Python is a programming language that has been growing in popularity in recent years. There are many reasons for this, but it mostly comes down to Python being easy to learn and use as well as the fact that Python has a very active community that develops amazing extensions to Python!\n",
    "\n",
    "In just the past few years, Python has become one of the most frequently used languages in the world of data science due to the ability to almost instantly apply it to a large number of data science problems. When asking companies in different industries and of various sizes what lanuage they would like their data scientists to know when coming in, they almost all agree that Python is the best choice. If you are going to learn one language (something everyone should do!), Python would be a great choice.\n",
    "\n",
    "From this language, other languages, features and packages have been created: Ipython, Pandas, Numpy, Matplotlib, and others that we will be using during this course. For more info please visit https://www.python.org/doc/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Jupyter Ipython notebooks\n",
    "\n",
    "One useful tool to work with Python is Jupyter, which has the Ipython notebooks.\n",
    "\n",
    "\"The IPython Notebook is now known as the Jupyter Notebook. It is an interactive computational environment, in which \n",
    "you can combine code execution, rich text, mathematics, plots and rich media. It is a web application that allows you to create and share documents that contain live code, equations, visualizations and explanatory text. Uses include: data cleaning and transformation, numerical simulation, statistical modeling, machine learning and much more.\"\n",
    "\n",
    "- Language: The Notebook has support for over 40 programming languages, including those popular in Data Science such as Python, R, Julia and Scala.\n",
    "\n",
    "- Sharing: Notebooks can be shared with others using email, Dropbox, GitHub and the Jupyter Notebook Viewer.\n",
    "\n",
    "- Widgets (apps): Code can produce rich output such as images, videos, LaTeX, and JavaScript. Interactive widgets can be used to manipulate and visualize data in realtime.\n",
    "\n",
    "\n",
    "For more details on the Jupyter Notebook, please see the Jupyter website http://jupyter.org/\n",
    "\n",
    "\n",
    "Steps to open a new notebook (you can open as many as you want!):\n",
    "\n",
    "\n",
    "![NewNotebook](images/new_notebook.png)\n",
    "\n",
    "\n",
    "\n",
    "This is how a new Ipython notebook looks:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "![NewNotebook](images/notebook.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Text files and scripts in Jupyter\n",
    "\n",
    "In jupyter, we can also create new text files or scripts.\n",
    "\n",
    "A script is just text known as \"command\". This text is defined in certain programming language (e.g. Python) and can be executed as a \"program\" without user interaction. We can know the language of the script based on the extension of the file. Then, for example, a file called \"script_example.py\" is a file with python commands, and a file called \"script_example.R\" is a file with the R language commands.\n",
    "\n",
    "Steps to open a new text file:\n",
    "\n",
    "![NewText](images/new_text.png)\n",
    "\n",
    "***\n",
    "\n",
    "This is how it looks:\n",
    "\n",
    "![Text](images/text.png)\n",
    "\n",
    "***\n",
    "\n",
    "Now we can change the language and write some examples of Python commands. \n",
    "\n",
    "We should change the extension of this file into a file.py to be able to run the file later.\n",
    "\n",
    "![Language](images/selectlanguage.png)\n",
    "![Language](images/script.png)\n",
    "\n",
    "\n",
    "Why do we need scripts? Because it is a good way to write commands that will be used frequently. Then, instead of writing all the commands in many notebooks, we can create a script and just call its commands. You will see how I do this in later labs!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Command line in Jupyter\n",
    "\n",
    "The command line is the way in which we interact with a computer program. From the command line (also known as terminal, or shell) you can perform almost any computer operation that you would normally use a mouse and graphical interface (GUI) for. In some cases, such as dealing with raw data files, the command line can give a quick way to start exploring. For example, we can use this to run scripts (like the one we just saw in the previous step). You have a terminal available in the Amazon system, but there is also one in your computer for your local system.\n",
    "\n",
    "For our class, we will only use the terminal to update our class material. This means that each time you want to get the new files that I have in the web (https://github.com/mariazm/Spring2017_ProfFosterProvost.git) you will need to open the terminal and write the command:   ~/sync_notebooks.sh\n",
    "\n",
    "(For more details look at the installations' assignment. Remember that running this command will replace all files in your folder \"Class_files\").\n",
    "\n",
    "\n",
    "Steps to open the terminal in Jupyter. \n",
    "\n",
    "![NewTerminal](images/new_terminal.png)\n",
    "\n",
    "This is how it looks when you open the terminal in jupyter and write some commands.\n",
    "\n",
    "![Terminal](images/terminal_2017.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command line tasks in a Jupyter Ipython Notebook\n",
    "\n",
    "\n",
    "Since we are not using the terminal, to communicate with the command line system we can use the Ipython Notebook.\n",
    "\n",
    "You can use shell commands (such as the following) in IPython notebooks by prefixing the line with an exclamation point.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interaction with files and folders\n",
    "\n",
    "We can navigate the folder structure where we are working (or in any machine you are). For this you will typically use commands such as `ls` (list) and `cd` (change directory). You can make a directory with `mkdir` or move (`mv`) and copy (`cp`) files. To delete a file you can `rm` (remove) it. To print the contents of a file you can `cat` (concatenate) it to the screen.\n",
    "\n",
    "Many commands have options you can set when running them. For example to get a listing of files as a vertical list you can pass the `-l` (list) flag, e.g. `ls -l`. During the normal course of using the command line, you will learn the most useful flags. If you want to see all possible options you can always read the `man` (manual) page for a command, e.g. `man ls`. When you are done reading the `man` page, you can exit by hitting `q` to quit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dealing with data.ipynb\r\n",
      "Ipython notebooks and files 2017.ipynb\r\n",
      "Programming Structures and Python Tour 2017.ipynb\r\n",
      "\u001b[34mdata\u001b[m\u001b[m\r\n",
      "\u001b[34mimages\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mkdir test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_notebook.png   notebook.png       terminal.png\r\n",
      "new_terminal.png   script.png         terminal_2017.png\r\n",
      "new_text.png       selectlanguage.png text.png\r\n"
     ]
    }
   ],
   "source": [
    "!ls images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cp images/terminal.png test/some_picture.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some_picture.png\r\n"
     ]
    }
   ],
   "source": [
    "!ls test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WARNING: THIS WILL DELETE THE TEST FOLDER JUST CREATED\n",
    "!rm -rf test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dealing with data.ipynb\r\n",
      "Ipython notebooks and files 2017.ipynb\r\n",
      "Programming Structures and Python Tour 2017.ipynb\r\n",
      "\u001b[34mdata\u001b[m\u001b[m\r\n",
      "\u001b[34mimages\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data manipulation and exploration\n",
    "Virtually anything you want to do with a data file can be done at the command line. There are dozens of commands that can be used together to get almost any result! Lets take a look at the the file `data/users.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do anything, lets take a look at the first few lines of the file to get an idea of what's in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user,variable1,variable2\r\n",
      "parallelconcerned,145.391881,-6.081689\r\n",
      "driftmvc,145.7887,-5.207083\r\n",
      "snowdonevasive,144.295861,-5.826789\r\n",
      "cobolglaucous,146.726242,-6.569828\r\n",
      "stylishmugs,147.22005,-9.443383\r\n",
      "hypergalaxyfibula,143.669186,-3.583828\r\n",
      "pipetsrockers,-45.425978,61.160517\r\n",
      "bracesworkable,-51.678064,64.190922\r\n",
      "spiritedjump,-50.689325,67.016969\r\n"
     ]
    }
   ],
   "source": [
    "!head data/users.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe we want to see a few more lines of the file,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user,variable1,variable2\r\n",
      "parallelconcerned,145.391881,-6.081689\r\n",
      "driftmvc,145.7887,-5.207083\r\n",
      "snowdonevasive,144.295861,-5.826789\r\n",
      "cobolglaucous,146.726242,-6.569828\r\n",
      "stylishmugs,147.22005,-9.443383\r\n",
      "hypergalaxyfibula,143.669186,-3.583828\r\n",
      "pipetsrockers,-45.425978,61.160517\r\n",
      "bracesworkable,-51.678064,64.190922\r\n",
      "spiritedjump,-50.689325,67.016969\r\n",
      "barnevidence,-68.703161,76.531203\r\n",
      "emeraldclippers,-18.072703,65.659994\r\n",
      "maintainwiggly,-14.401389,65.283333\r\n",
      "submittedwavelength,-15.227222,64.295556\r\n",
      "clucklinnet,-17.425978,65.952328\r\n"
     ]
    }
   ],
   "source": [
    "!head -15 data/users.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about the last few lines of the file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "troubledseptum,135.521667,-29.716667\r\n",
      "troubledseptum,-118.598889,34.256944\r\n",
      "organicmajor,-5.435,36.136\r\n",
      "cobolglaucous,-123.5,48.85\r\n",
      "troubledseptum,-124.016667,49.616667\r\n",
      "snaildossier,-124.983333,50.066667\r\n",
      "unbalancedprotoplanet,-127.028611,50.575556\r\n",
      "badgefields,-126.833333,50.883333\r\n",
      "backedammeter,-123.00596,48.618397\r\n",
      "clucklinnet,-117.1995,32.7552\r\n"
     ]
    }
   ],
   "source": [
    "!tail data/users.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can count how many lines are in the file by using `wc` (a word counting tool) with the `-l` flag to count lines,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    8104 data/users.csv\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l data/users.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there are three columns in this file, lets take a look at the first one alone. Here, we can `cut` the field (`-f`) we want as long as we give the proper delimeter (`-d` defaults to tab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cut -f1 -d',' data/users.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of output. Let's combine the `cut` command with the `head` command by _piping_ the output of one command into another one,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\r\n",
      "parallelconcerned\r\n",
      "driftmvc\r\n",
      "snowdonevasive\r\n",
      "cobolglaucous\r\n",
      "stylishmugs\r\n",
      "hypergalaxyfibula\r\n",
      "pipetsrockers\r\n",
      "bracesworkable\r\n",
      "spiritedjump\r\n"
     ]
    }
   ],
   "source": [
    "!cut -f1 -d',' data/users.csv | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use pipes (`|`) to string together many commands to create very powerful one liners. For example, lets get the number of unique users in the first column. We will get all values from the first column, sort them, find all unique values, and then count the number of lines,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     201\r\n"
     ]
    }
   ],
   "source": [
    "!cut -f1 -d',' data/users.csv | sort | uniq | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, we can get a list of the top-10 most frequently occuring users. If we give `uniq` the `-c` flag, it will return the number of times each value occurs. Since these counts are the first entry in each new line, we can tell `sort` to expect numbers (`-n`) and to give us the results in reverse (`-r`) order. Note, that when you want to use two or more single letter flags, you can just place them one after another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  59 compareas\r\n",
      "  56 upbeatodd\r\n",
      "  56 burntrifle\r\n",
      "  56 binomialapathetic\r\n",
      "  54 frequencywould\r\n",
      "  54 ellipticalfabricator\r\n",
      "  53 globeshameful\r\n",
      "  52 badgefields\r\n",
      "  52 ashamedmuscles\r\n",
      "  51 alloweruptions\r\n"
     ]
    }
   ],
   "source": [
    "!cut -f1 -d',' data/users.csv | sort | uniq -c | sort -nr | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some exploration we decide we want to keep only part of our data and bring it into a new file. Let's find all the records that have a negative value in the second and third columns and put these results in a file called `data/negative_users.csv`. Searching through files can be done using _[regular expressions](http://www.robelle.com/smugbook/regexpr.html#expression)_ with a tool called `grep` (Global Regular Expression Printer). You can direct output into a file using a `>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!grep '.*,-.*,-.*' data/users.csv > data/negative_users.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the data folder to see if our new file is in there,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds_survey.csv      negative_users.csv users.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
